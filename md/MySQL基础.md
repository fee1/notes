# MySQL基础

## 简介

### 什么是SQL？

- 结构化查询语言(structured query language)简称SQL，是一种数据库查询语言。
- 作用：用于存取数据、查询、更新和管理关系数据库系统

### 什么是MySQL？

- MySQL是一个关系型数据库系统，由瑞典MySQL AB公司开发，属于Oracle旗下产品。

### 什么是数据库三大范式？

- 1.第一范式：每个列都不可再拆分。
- 2.第二范式：在第一范式的基础上，非主键完全依赖于主键，而不能是依赖于主键的一部分
- 3.第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键

### MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在MySQL数据库里，由mysql_install_db脚本初始化。这些权限分别user，db，table_priv，columns_priv和host。

- user权限表

	- 记录允许连接到服务器的用户账号信息，里边的权限是全局级别的

- db权限表

	- 记录个账号在各数据库上的操作权限

- table_priv权限表

	- 记录数据表级的操作权限

- columns_priv权限表

	- 记录数据列级的操作权限

- host权限表

	- 配合db权限表对给定主机上数据库级操作其权限作更细致的控制。这个权限表不受grant和revoke语句的影响

### MySQL的binlog有几种录入格式？分别有什么区别？

- 三种格式：

	- 1.statement

		- statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制

			- 记录sql上下文信息，日志量少，节约io，性能高

	- 2.row

		- row级别下，不记录sql语句上下文相关信息，仅保存那条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存信息太多，日志量太大

			- 不记录上下文信息，但是每一条记录的变化都会被记录下来，日志量很大

	- 3.mixed

		- mixed，一种这种方案，普通操作使用statement记录，当无法使用statement的时候使用row

			- 前两种的折中方案

## 数据类型

### MySQL的数据类型

- 一个字节是8位，最高位是符号位，最高位为0则是正数。最高位为1则是负数

	- 如果一个数是正数，最大数则为：01111111，转为十进制为127，如果一个数是负数，按照一般人都会觉得是11111111，转为十进制为-127

- 数字类型

	- 图：

		- 1.任何整数类型都可以加上unsigned属性，表示数据是无符号的，即非负数
		- 2.整数类型可以指定长度，但是没有意义，他不会限制值的合法范围，只会影响显示字符的个数，而且需要和unsigned zerofill属性配合使用才有意义。例：

			- 假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。

		- 3.Decimal可以用于存储比bigint还大的整型，能存储精确的小数。

float和double是有取值范围的，并支持使用标准的浮点进行近似计算。

float和double相比decimal效率更高一些，decimal可以理解成是字符串进行处理

- 日期时间类型

	- 图：

		- 1.尽量使用timestamp，空间效率高于datetime
		- 2.如果要存储微妙，可以使用Bigint

- 字符串类型

	- 图：

		- 1.varchar用于存储可变长字符串，它比定长类型更节省空间
		- 2.varchar使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示
		- 3.varchar存储内容超出设置的长度时，内容会被截断
		- 4.char时定长的，根据定义的字符串长度分配足够的空间
		- 5.char会根据需要使用空格进行填充方便比较
		- 6.char适合存储很短的字符串，内容超过长度，一样会被截断
		- 使用策略：

			- 1.对于经常变更的数据，char比varchar更好，因为char不容易产生碎片
			- 2.对于非常短的列，char比varchar在存储空间上更有效率
			- 3.使用时要注意只分配需要的空间，更长的列排序时会消耗更多的内存
			- 4. 尽量避免使用text/blob类型，查询时会使用临时表，导致严重的性能开销

## 引擎

### MyISAM

- 不支持事务，也不支持行级锁和外键

### InnoDB

- 提供对数据库ACID事务支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统

### MyISAM与InnoDB的区别：

### InnoDB引擎的4大特性：

- 1.插入缓冲(insert buffer)
- 2.二次写(double write)
- 3.自适应哈希索引(ahi)
- 4.预读(read ahead)

### 问题：

- 1.MyISAM索引与InnoDB索引的区别？

	- 1.InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引
	- 2.InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效
	- 3.MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才得到数据
	- 4.InnoDB非主键索引的叶子节点存储的是主键和其他索引的列数据

- 2.InnoDB引擎的4大特性

	- 1.插入缓冲(insert buffer)
	- 2.二次写(double wirte)
	- 3.自适应哈希索引(ahi)
	- 4.预读(read ahead)

- 3.存储引擎的选择

	- 1.如果没有什么特殊的需求，使用默认的InnoDB即可
	- 2.MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站
	- 3.InnoDB：更新删除操作频率高，或者保证数据完整性；并发量高，支持事务和外键。比如OA自动化办公系统

## 索引

### 索引的优缺点

- 优点

	- 1.可以大大加快数据的检索速度，这也是创建索引的最主要原因
	- 2.通过索引，查询过程中，使用优化隐藏器，提高系统性能

- 缺点

	- 1.时间方面：创建和维护索引要消耗时间，具体就是，当数据增加、删除和修改的时候，索引也要动态的维护，会降低增删改的执行效率
	- 2.空间方面：索引需要占物理空间

### 索引使用场景(重点)

- 1.where

	- 提升sql的查询效率

- 2.order by

	- 如果该字段没有建立索引，那么执行计划会将查出的所有数据使用外部排序(把所有结果从硬盘读取到内存再排序)，这个操作很影响性能，特别是数据量很多或者单条数据很大的时候。

		- 索引本身就是有序的，需要去除索引表的某个范围内的索引对象的数据，不用像上诉那样去除所有数据进行排序再返回某个范围内的数据

- 3.join

	- 对join语句匹配关系(on)涉及的字段未建立索引能够提高效率

- 4.索引覆盖

	- 如果要查询的字段都建立的索引，那么引擎直接再索引表中查询不会访问原始数据，这叫做索引覆盖。但并不是所有字段都要建索引，优先使用索引的优势就是在于体积小

## 索引类型

### 1.主键索引

- 数据列不允许重复，不允许为null，一个表只能有一个主键

### 2.唯一索引

- 数据列不允许重复，允许为null值，一个表允许多个列创建唯一索引

	- 普通唯一：ALTER TABLE table_name ADD UNIQUE (column)
	- 组合唯一：ALTER TABLE table_name ADD UNIQUE (column1,column2)

### 3.普通索引

- 普通索引类型，没有唯一性限制，允许为null值

	- 普通：ALTER TABLE table_name ADD INDEX index_name (column)
	-  组合：ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3)

### 4.全文索引

- 是目前搜索引擎的一种关键技术

	- ALTER TABLE table_name ADD FULLTEXT (column)

## 索引结构

### 1.B树索引

- InnoDB的索引类型目前只有两种：B树索引和Hash索引。BTree是使用最频繁的索引，基本所有查询引擎都支持BTree
- 图：
- 查询方式：

	- 1.主键索引区：PI(关联保存的时候数据的地址)按主键查询
	- 2.普通索引区：SI(关联的id的地址，然后再到达上面的地址)。所以按主键查询，速度最快

- B+tree性质：

	- 1.n个子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引
	- 2.所有的叶子节点包含了列字段信息，叶子节点按照字段的大小自小而大排序连接
	- 3.B+树中，数据对象的插入和删除仅在叶子节点上进行
	- 4.B+树有两个头指针，一个是树的根节点，一个是最小关键码的叶节点

### 2.哈希索引

- 我们在mysql中哈希索引，主要通过hash算法。将数据库字段数据转换成定长的hash值，与这条数据的行指针一并存入hash表对应位置；如果发生hash碰撞(两个不同关键字的hash值相同)，则在对应hash键下以链表形式存储
- 图：
- hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值大量存在重复的时候，发生hash碰撞，此时效率可能极差。B+树查询效率比较稳定，因此大多数情况下，直接选择B+数索引可以获得稳定且较好的性能。而不需要选择hash索引

## 索引的基本原理

### 索引的原理很简单，就是把无序的数据变成有序的查询

- 1.把创建的索引的列的内容进行排序
- 2.对排序结果生成倒排表
- 3.在倒排表内容上拼上数据地址链
- 4.在查询的时候，先拿到倒排表内容，再取数据地址链，从而拿到具体数据

## 索引的算法

### BTree算法

- mysql默认算法，可以用在=,>,>=,<,<=和between，like上

### Hash算法

- 只能使用对等比较，例如=操作符。一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，检索效率远高于BTree索引

## 索引设计原则

### 1.出现在where子句中的列，适合建立索引的列

### 2.基数较小的类，索引效果较差，没有必要在此建立索引

### 3.使用短索引，如果对长字符索引，应该指定一个前缀长度，这样能够节省大量索引空间

### 4.不要过度使用索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只需要索引有利于查询即可

## 创建索引的原则(重要)

### 1.最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围内查询(>,<,between,like)就停止匹配，比如a=1 and b=2 and c>3 and d=4如果建立(a,b,c,d)顺序索引，d是用不到索引的，如果改成(a,b,d,c)顺序就可以都用到

### 2.较频繁作为查询条件的字段才去创建索引

### 3.更新频繁的字段不适合创建索引

### 4.若是不能有效区分数据的列不适合做索引列(如性别，区分度太低)

### 5.尽量扩展索引，不要新建索引。比如表中已经有了a的索引，现在要加(a,b)索引，只需要修改原来的索引即可

### 6.定义有外键的数据列一定要建立索引

### 7.对于那些查询中很少涉及的列，重复值比较多的列不要建立索引

### 8.对于定义为text、image和bit的数据类型的列不要建立索引

## 创建索引的三种方式

### 1.在执行create table的时候创建索引

CREATE TABLE user_index2 (
 id INT auto_increment PRIMARY KEY,
 first_name VARCHAR (16),
 last_name VARCHAR (16),
 id_card VARCHAR (18),
 information text,
 KEY name (first_name, last_name),
 FULLTEXT KEY (information),
 UNIQUE KEY (id_card)
);



### 2.使用alter table命令去增加索引

ALTER TABLE table_name ADD INDEX index_name (column_list);



### 3.使用create index创建

CREATE INDEX index_name ON table_name (column_list);



### 删除索引

alter table 表名 drop KEY 索引名
alter table user_index drop KEY name;
alter table user_index drop KEY id_card;
alter table user_index drop KEY information;



### 问题：

- 1.创建索引时需要注意什么？

	- 1.非空字段

		- 应该指定列为not null，除非你想存储null。在mysql中，含有空值的列很难进行查询优化，因为他们使得索引、索引的统计信息以及比较运算更加复杂。你应该使用0、一个特殊的值或一个空字符串代替空值

	- 2.取值离散大的字段

		- 变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高

	- 3.索引字段越小越好

		- 数据库数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高

- 2.使用索引查询一定能提高查询性能吗？为什么？

	- 1.索引需要空间来存储，也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的Insert、delete、update将为此付出4，5次磁盘IO。因为索引需要额外的存储空间和处理，那些不必要的索引反而会时查询反应时间变慢。使用索引查询不一定能提升查询性能
	- 2.基于一个范围检索，一般查询返回结果集小于表记录数的30%
	- 3.基于非唯一性索引的检索

- 3.百万级别或以上的数据如何删除？

	- 我们删除数据库百万级别数据的时候，删除数据的熟读和创建的索引数量是成正比的
	- 1.先删除索引
	- 2.删除其中无用的数据
	- 3.删除完后重新创建索引

- 4.B树和B+树的区别？

	- 1.B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值

		- 有序数组+平衡多叉树

	- 2.B+树的叶子节点有一条链相连，而B树的叶子系欸但各自独立

		- 有序数组链表+平衡多叉树

	- 图：

- 5.使用B树的好处？

	- B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近跟节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数量数据重复多次查询的场景中更加高效

- 6.使用B+树的好处？

	- B+树内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的值，有利于更快的缩小查找范围。B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间

- 7.为什么数据库使用B+树而不是B树？

	- 1.B树只适合随机检索，B+树同时支持随机检索和顺序检索
	- 2.B+树空间利用率更高，可减少IO次数，磁盘读写代价更低
	- 3.B+树查询效率更稳定
	- 4.B树在提高了磁盘IO性能的同时并没有解决元素遍历效率低下的问题
	- 5.增删文件时，效率更高

- 8.B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据
- 9.什么时聚簇索引？什么是非聚簇索引？

	- 聚簇索引：将数据存储和索引放到一块，找到索引也就找到了数据
	- 非聚簇索引：将数据存储与索引分开结构，索引结构

- 10.非聚簇索引一定会回表查询吗？

	- 不一定，如果查询语句所要求的全部字段都命中了索引，那么就不需要进行回表查询了

## 事务

### 什么是数据库事务？

- 事务时不可以分割的数据库操作序列，也是数据库并发控制的基本单位，其执行结果必须使用数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上一组操作，要么全部执行，要么都不执行

### 事务四大特性

- 1.原子性

	- 事务是最小的执行单位，不允许分割。要么全部完成，要么完全不起作用

- 2.一致性

	- 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果都是形同的

- 3.隔离性

	- 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的

- 4.持久性

	- 一个事务提交之后，它对数据库的改变是持久的，不可回滚的

### 什么是脏读？幻读？不可重复读？

- 脏读

	- 某个事务读取到了另一个事务未提交的数据，那个数据可能会回滚，就导致脏数据

- 不可重复读

	- 某一个事务两次查询同一数据不一致，被其他事务更改过。主要是更新数据方面问题

- 幻读

	- 某个事务两次查询到的数据量不对，主要是添加删除数据问题

### 事务的隔离级别

- 1.读未提交

	- 允许读未提交的数据，会导致脏读、不可重复读、幻读

- 2.读已提交

	- 允许读并发事务已经提交的数据，可以防止脏读，还是会出现不可重复读，幻读

- 3.可重复读

	- 对同一字段多次读取的数据结果都是一样的。可以阻止脏读、不可重复读，但是幻读还是存在

- 4.可串行化

	- 可以防止所有问题

## 锁

### 隔离级别与锁的关系

- 1.read uncommitted

	- 读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突

- 2.read committed

	- 读操作需要加共享锁，但是在语句执行完以后释放共享锁

- 3.repeatable read

	- 读操作需要加共享锁，但是事务提交之前不释放共享锁，也就是必须等待事务执行完毕之后才释放共享锁

- 4.serializable

	- 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成

### 锁的粒度

- MyISAM和InnoDB存储引擎使用的锁

	- MyISAM

		- 采用表级锁

	- InnoDB

		- 支持行级锁和表级锁，默认为行级锁

- 行级锁

	- 行级锁是MySQL中锁定粒度最细大的一种锁，表示只针对当前操作的行进行加锁。

- 表级锁

	- 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁

- 页级锁

	- 介于行级锁和表级锁中间的一种锁

### 锁的类别

- 1.共享锁

	- 又叫做读锁

		- 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个

- 2.排他锁

	- 又叫做写锁

		- 当用户要进行数据的写入时，对数据加上排他锁。排他锁可以加一个他和其他的排他锁，共享锁都互斥

### MySQL中的InnoDB引擎的行锁时怎么是实现的？

- InnoDB基于索引来完成行锁，没有使用索引，将使用表级锁

  例: select * from tab_with_index where id = 1 for update;
  
  for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起
  
  

## SQL

### SQL语句分类

- 1.DDL

	- create、drop、alter

- 2.DQL

	- select

- 3.DML

	- insert、update、delete

- 4.DCL

	- grant、revoke、commit、rollback

### 键

- 超键

	- 在关系中能唯一表示元组的属性集称为关系模式的超键。超键包含候选键和主键

- 候选键

	- 是最小超键，即没有冗余元素的超键

- 主键

	- 数据库表中对数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值null

- 外键

	- 在一个表中存在的另一个表的主键称为此表的外键

### 约束

- not null

	- 控制字段内容不能为空(null)

- unique

	- 控制字段内容不能重复，一个表允许有多个Unique约束

- primary key

	- 表只允许出现一个，字段内容不能重复

- foreign key

	- 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一

- check

	- 用于控制字段的值范围

### 关联查询

- 交叉查询(cross join)
- 内连接(inner join)
- 外连接(left join/right join)
- 联合查询(union/union all)

	- 两者区别

		- 1.如果使用union all，不会合并重复记录的行
		- 2.效率union all高于union

- 全连接(full join)

### 子查询

- 1.条件

	- 一条sql语句查询结果作为另一条查询语句的条件或查询结果

- 2.嵌套

	- 多条sql语句嵌套使用，内部的sql从查询语句称为子查询

### in和exists的区别

- in语句是把外表和内表做hash连接，而exists语句是对外表作loop循环，每次loop循环在对内表进行查询。大家都认为exists比in语句的效率要高，这种说法不准确，需要区分环境

	- 1.如果查询的两个表相当，那么用in和exists差别不大
	- 2.如果两个表中一个较小，一个大表，则子查询表大的用exists，子查询表小的用in
	- 3.not in和not exists：如果使用了not in，那么内外表都进行全表扫描，没有用到索引。not exists的子查询依然能用到表上的索引，无论那个表大，用not exists都比not in要快

### 生命周期

- 1.应用服务器与数据库服务器建立一个连接
- 2.数据库进程拿到请求sql
- 3.解析并生成执行计划，执行
- 4.读取数据到内存并进行逻辑处理
- 5.通过步骤一的连接，发送结果给客户端
- 6.关掉连接，释放资源
- 图：

### 分页

- limit

	- 例：mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15 

第一个参数指定第一个返回记录行的偏移量，第二个参数时返回记录行的最大数目

## SQL优化

### MySQL提供explain命令来查看语句的执行计划

- 图：
- id

	- id相同执行顺序由上至下
	- id不同，id值越大，越先被执行
	- id为null是表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中

- select_type

	- 1.simple

		- 不包含任何子查询或union等查询

	- 2.primary

		- 包含子查询最外层查询就显示为primary

	- 3.subquery

		- 在select或where子句中包含的查询

	- 4.derived

		- from字句中包含的查询

	- 5.union

		- 出现在union后的查询语句中

	- 6.union result

		- 从union中获取结果集，例如上文的第三个例子

- table

	- 查询的数据表

- type

	- 访问的类型

		- all

			- 扫描全表数据

		- index

			- 遍历索引

		- range

			- 索引范围查询

		- index_subquery

			- 在子查询中使用ref

		- unique_subquery

			- 在子查询中使用了eq_ref

		- ref_or_null

			- 对null进行索引的优化的ref

		- fulltext

			- 使用全文索引

		- ref

			- 使用非唯一索引从查找数据

		- eq_ref

			- 在join查询中使用primary key或unique not null索引关联

- possible_keys

	- 可能使用的索引，注意不一定会使用

- key

	- 显示mysql在查询中实际使用的索引，若没有使用索引，显示为null

- key_length

	- 索引长度

- ref

	- 表示上述表的连接匹配条件，即那些列或常量被用于查找索引列上的值

- rows

	- 返回估值的结果集数据，并不一定是准确的值

- extra

	- 常见：

		- 1.using index

			- 使用覆盖索引

		- 2.using where

			- 使用了用where子句来过滤结果集

		- 3.using filesort

			- 使用文件排序，使用非索引列进行排序时常出现，非常消耗性能(读取结果到内存再进行排序)

		- 4.using temporary

			- 使用临时表

### 大表数据查询，怎么优化？

- 1.优化shema、sql语句+索引
- 2.第二加缓存，memcached，redis
- 3.主从复制，读写分离
- 4.垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统
- 5.水平拆分，针对数据量大大的表，这一步最麻烦，最能考验技术水平，选择一个合理的sharding key，为了有好的查询效率，表结构也要改动，做到一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表

### 超大分页怎么处理？

- 1.数据库层面

	-  减少load的数据

		- 例：select * from table where age > 20 limit 1000000,10这种查询其实也是有可以优化的余地的这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为select * from table where id in (select id from table where age > 20 limit 1000000,10)。这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以select * from table where id > 1000000 limit 10,

- 2.需求角度

	- 解决超大分页其实主要时靠缓存，可预测性提前查到内容，缓存至redis等k-v数据库中，直接返回即可

		- 例：【推荐】利用延迟关联或者子查询优化超多分页场景。 

说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 

正例：先快速定位需要获取的id段，然后再关联： 

SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id


### 慢查询日志

- 简介：用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考
- 开启慢查询日志

	- 查看是否开启

		- show variables like ‘slov_query_log’

			- OFF：表示未开启

	- 设置开启

		- set GLOBAL slow_query_log = on

			- 它会在datadir下产生一个xxx-slow.log的文件

- 设置临界时间

	- 查看

		- show VARIABLES like 'long_query_time'，单位秒

	- 设置

		- set long_query_time=0.5

### 如何优化查询sql？

- 1.使用explain进行分析
- 2.分析是否访问数据太多导致查询性能下降，很多不是我们需要查询的列
- 3.是否返回了我们不需要的列，所以不要使用*
- 4.多次查询相同的数据，我们应该使用缓存

### 字段为什么要定义not null？

- null值会占用更多的字节，且会程序中造成很多与预期不符的情况

### 如果存储密码散列，应该使用什么字段进行存储？

- 密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率

### 优化长难的查询语句？

- 1.尽可能小的查询，将一个大的查询分解为多个小的查询是很有必要的
- 2.一次性删除1000万的数据要比一次删除出1w，暂停一会的方案更加损耗服务器开销
- 3.分解关联查询，让缓存的显效率更高
- 4.指定单个查询可以减少锁的竞争
- 5.在应用层做关联更容易对数据库进行拆分
- 6.减少冗余记录的查询

### 优化特定类型的查询语句？

- 1.count(*)会忽略所有列，直接统计所有列数，不要使用count(列名)
- 2.MyISAM中，没有任何where条件的count(*)非常块
- 3.有where条件时，MyISAM的count统计不一定比其他引擎快
- 4.可以使用explain查询近似值，用近似值代替count(*)
- 5.使用缓存

### 优化关联查询

- 确定on或者using子句是否有索引
- 确保group by和order by只有一个表中的列，这样的mysql才有可能使用索引

### 优化limit分页

- 1.limit偏移量大的时候，查询效率较低
- 2.可以记录上次查询的最大ID，下次查询时，直接根据该ID来查询

### 优化union查询

- union all效率高于union

### 优化where子句

- 1.对查询进行优化，应尽量避免全表扫描，首先考虑在where及order by涉及的列上建立索引
- 2.应尽量避免在where子句中对字段进行null判断，这会导致引擎放弃使用索引而进行全表扫描

	- select id from t where num is null
-- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：
select id from t where num=


- 3.应尽量避免在where子句中使用!=或<>操作符，会时引擎放弃使用索引而进行全表扫描
- 4.应尽量避免where子句中使用or来连接条件，否则将会导致放弃使用索引而进行全表扫描

	- select id from t where num=10 or num=20
-- 可以这样查询：
select id from t where num=10 union all select id from t where num=20


- 5.in 和 not in也要慎重使用，否则会导致全表扫描

	- select id from t where num in(1,2,3) 
-- 对于连续的数值，能用 between 就不要用 in 了：
select id from t where num between 1 and 3


- 6.%李%若要考虑提高效率，可以考虑全文检索
- 7.在where子句中使用参数，也会导致全表扫描

	- select id from t where num=@num
-- 可以改为强制查询使用索引：
select id from t with(index(索引名)) where num=@num


- 8.应尽量避免在where子句中对字段进行表达式操作，会导致引擎放弃使用索引而进行全表扫描

	- select id from t where num/2=100
-- 应改为:
select id from t where num=100*2


- 9.尽量避免在where子句中对字段进行函数操作，这会导致引擎放弃使用索引而进行全表扫描

	- select id from t where substring(name,1,3)=’abc’
-- name以abc开头的id应改为:
select id from t where name like ‘abc%’


- 10.不要在where子句中的"="左边进行函数、算数运算或其他表达式运算，否则系统可能无法正确使用缩影

## 数据库优化

### 为什么要优化？

- 1.系统吞吐量瓶颈往往出现在数据库的访问上
- 2.随着应用程序的运行，数据库中的数据会越来越多，处理时间会相应变慢
- 3.数据是存放在磁盘上的，读写速度无法和内存相比
- 优化原则：减少系统瓶颈，减少资源占用，增加系统的反应速度

### 数据库结构优化

- 1.见字段很多的表分解成多个表

	- 一个表的数据量很大时，会由于使用频率低的字段存在而变慢

- 2.增加中间表

	- 对于需要经常联合查询的表，可以建立中间表以提高查询效率

- 3.减少冗余字段

### mysql数据库cpu飙升500%怎么处理？

- 1.先用操作系统命令 top 命令观察是不是 mysqld 占用导致的
- 2.mysqld 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。
- 3.也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等

### 大表怎么优化？某个表近千万的数据，CRUD比较慢，如何优化？分库分表怎么做？分库分表有神恶魔问题？有用到中间件吗？知道原理吗？

- 常见的优化措施

	- 1.限制数据的范围

		- 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内

	- 2.读写分离

		- 主库负责写，从库负责读

			- 减少锁的性能影响

	- 3.缓存

- 1.垂直拆分

	- 图：
	- 优点

		- 可以使得行数据变小，查询时减少读取的block树，减少IO次数。垂直拆分可以简化表结构，易于维护

	- 缺点

		- 主键冗余，需要管理冗余列，并引起join操作，可以通过应用层解决

	- 适用场景

		- 1.如果一个表中的某些列常用，另外一些列不常用
		- 2.可以使数据行变小，一个数据页能存储更多数据，查询时减少IO次数

- 2.水平拆分

	- 图：
	- 适用场景

		- 1.表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别时有些数据常用，有些不常用
		- 2.需要把数据放在多个介质上

	- 缺点

		- 增加系统复杂度，通常查询时需要多个表名，查询所有数据都需要UNION操作
		- 在许多数据库应用中，这种复杂度超过它带来的优点，查询时会增加读一个索引层的磁盘数

	- 常见方案

		- 1.客户端代理

			- 分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。当当网的sharding-JDBC、阿里的TDDL是两种常见的实现

		- 2.中间件代理

			- 在应用和数据中间增加一个代理层。分片逻辑统一维护在中间件服务中。 我们现在谈的 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现

### 分库分表后面临的问题

- 事务支持
- 跨库join
- 跨节点的count，order by， group by以及聚合函数问题
- 数据迁移，容量规划，扩容等问题
- ID问题

## MySQL主从复制

### 原理

- 将数据DDL和DML操作通过二进制日志(binlog)传输到从数据库上，然后将这些日志重新执行(重做)；从而使得这些数据库得数据和主数据库保持一致

### 作用

- 1.主数据库出了问题，可以切换到从数据库
- 2.可以进行数据库层面的读写分离
- 3.可以在从数据库上进行日常备份

### 解决的问题

- 1.数据分布

	- 随意开始或停止复制，并在不同地理位置分布数据备份

- 2.负载均衡

	- 降低单个服务器的压力

- 3.高可用和故障切换

	- 帮助应用程序避免单点失败

- 4.升级测试

	- 可以用更高版本的MySQL作为从库

### 工作原理

- 1.在主库上把数据更高记录到二进制日志
- 2.从库将主库的日志复制到自己的中继日志
- 3.从库读取中级日志的事件，将去重放到从库数据中

### 基本原理流程，3个线程以及之间的关联

- 主

	- binlog线程，记录下所有改变了数据库数据的语句，放进master上的binlog中

- 从

	- IO线程，在使用start slave之后，负责从master上拉取binlog内容，放进自己的relay log中

- 从

	- sql执行线程，执行relay log的语句

### 图：

- Binary log：主数据库的二进制日志
- relay log：从服务器的中继日志
- 第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中
- 第二步：slave开启一个IO thread，该线程在master打开一个普通链接，主要工作使binlog dump process。如果读取地进度已经跟上master，就进入睡眠状态并等待master产生新的事件。IO线程最终地目的就是将这些事件写入到中继日志中。
- 第三步：SQL Thread会读取中继日志，并顺序执行该日志中地SQL事件，从而与主数据库中地数据保持一致

### 方案

- 方案一

	- 使用mysql-proxy代理

		- 优点 

			- 直接实现读写分离和负载均衡，不用修改代码，master和slave用一样的账号，mysql官方不建议实际生产中使用

		- 缺点

			- 降低性能，不支持事务

- 方案二

	- 使用AbstractRoutingDataSource+aop+annotation在dao层决定数据源

		- 如果采用了mybatis， 可以将读写分离放在ORM层，比如mybatis可以通过mybatis plugin拦截sql语句，所有的insert/update/delete都访问master库，所有的select 都访问salve库，这样对于dao层都是透明。 plugin实现时可以通过注解或者分析语句是读写方法来选定主从库。不过这样依然有一个问题， 也就是不支持事务， 所以我们还需要重写一下DataSourceTransactionManager， 将read-only的事务扔进读库， 其余的有读有写的扔进写库。

- 方案三

	- 使用AbstractRoutingDataSource+aop+annotation在service决定数据源，可以支持事务
	- 缺点：类内部方法通过this.xx()方式相互调用时，aop不会拦截，需要特殊处理

## 备份

### 备份计划

- 视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。

100G 以上的库，可以考虑用 xtranbackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。

### 备份恢复时间

- 物理备份恢复快，逻辑备份恢复慢

这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考

20G的2分钟（mysqldump）

80G的30分钟(mysqldump)

111G的30分钟（mysqldump)

288G的3小时（xtra)

3T的4小时（xtra)

逻辑导入时间一般是备份时间的5倍以上

### 备份恢复失败如何处理

- 首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。

### mysqldump和xtrabackup实现原理

- mysqldump

	- mysqldump 属于逻辑备份。加入–single-transaction 选项可以进行一致性备份。后台进程会先设置 session 的事务隔离级别为 RR(SET SESSION TRANSACTION ISOLATION LEVELREPEATABLE READ)，之后显式开启一个事务(START TRANSACTION /*!40100 WITH CONSISTENTSNAPSHOT */)，这样就保证了该事务里读到的数据都是事务事务时候的快照。之后再把表的数据读取出来。如果加上–master-data=1 的话，在刚开始的时候还会加一个数据库的读锁(FLUSH TABLES WITH READ LOCK),等开启事务后，再记录下数据库此时 binlog 的位置(showmaster status)，马上解锁，再读取表的数据。等所有的数据都已经导完，就可以结束事务

- Xtrabackup

	- xtrabackup 属于物理备份，直接拷贝表空间文件，同时不断扫描产生的 redo 日志并保存下来。最后完成 innodb 的备份后，会做一个 flush engine logs 的操作(老版本在有 bug，在5.6 上不做此操作会丢数据)，确保所有的 redo log 都已经落盘(涉及到事务的两阶段提交

概念，因为 xtrabackup 并不拷贝 binlog，所以必须保证所有的 redo log 都落盘，否则可能会丢最后一组提交事务的数据)。这个时间点就是 innodb 完成备份的时间点，数据文件虽然不是一致性的，但是有这段时间的 redo 就可以让数据文件达到一致性(恢复的时候做的事

情)。然后还需要 flush tables with read lock，把 myisam 等其他引擎的表给备份出来，备份完后解锁。这样就做到了完美的热备。

### 数据表损坏的修复方式有哪些

- 使用 myisamchk 来修复，具体步骤

	- 1）修复前将mysql服务停止。
	- 2）打开命令行方式，然后进入到mysql的/bin目录。
	- 3）执行myisamchk –recover 数据库所在路径/*.MYI
	- 使用repair table 或者 OPTIMIZE table命令来修复，REPAIR TABLE table_name 修复表 OPTIMIZE TABLE table_name 优化表 REPAIR TABLE 用于修复被破坏的表。 OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了OPTIMIZE TABLE命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库）

